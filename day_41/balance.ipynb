{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "410ee53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# NumPy generates random numbers using a pseudo-random number generator (PRNG).\n",
    "np.random.seed(123)\n",
    "\n",
    "sample_data = 1000\n",
    "class_0_ratio = 0.9\n",
    "class_0_data = int(sample_data * class_0_ratio) # first data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03ee49bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1_data = sample_data - class_0_data # second data\n",
    "class_1_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adb5853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  target\n",
      "0 -1.085631  0.551302       0\n",
      "1  0.997345  0.419589       0\n",
      "2  0.282978  1.815652       0\n",
      "3 -1.506295 -0.252750       0\n",
      "4 -0.578600 -0.292004       0\n",
      "     feature1  feature2  target\n",
      "995  0.376371  1.845701       1\n",
      "996  1.239810 -0.119923       1\n",
      "997  0.131760  0.640703       1\n",
      "998  1.902006 -0.609695       1\n",
      "999  1.697490  1.013570       1\n"
     ]
    }
   ],
   "source": [
    "# Generate features for class zero\n",
    "feature1_class_zero = np.random.normal(loc=0, scale=1, size=class_0_data)\n",
    "feature2_class_zero = np.random.normal(loc=0, scale=1, size=class_0_data)\n",
    "\n",
    "\n",
    "# Generate features for class one\n",
    "feature1_class_one = np.random.normal(loc=1, scale=1, size=class_1_data)\n",
    "feature2_class_one = np.random.normal(loc=1, scale=1, size=class_1_data)\n",
    "\n",
    "\n",
    "# Create dataframes\n",
    "class_zero_df = pd.DataFrame({\n",
    "    'feature1': feature1_class_zero,\n",
    "    'feature2': feature2_class_zero,\n",
    "    'target': 0\n",
    "})\n",
    "\n",
    "class_one_df = pd.DataFrame({\n",
    "    'feature1': feature1_class_one,\n",
    "    'feature2': feature2_class_one,\n",
    "    'target': 1\n",
    "})\n",
    "\n",
    "# Combine dataframes\n",
    "df = pd.concat([class_zero_df, class_one_df], ignore_index=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2148a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the total number of data \n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "305ead62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one the major method to balance the data in upsampling \n",
    "# major number of data\n",
    "df_major = df[df['target']==0]\n",
    "# minor number of data\n",
    "df_minor = df[df['target'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cfca89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# We resample the minority class with replacement to increase its size to match the majority class.\n",
    "df_minor_upsampled = resample(\n",
    "    df_minor,\n",
    "    replace=True,  # sample with replacement\n",
    "    n_samples=len(df_major),  # match number in majority class\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_minor_upsampled['target'].value_counts()\n",
    "# now the upsampled value is 900 it means we balance the minor values and make it similar with major values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa2d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled = pd.concat([df_major,df_minor_upsampled])\n",
    "# counts the value\n",
    "df_upsampled['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f065d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same data\n",
    "# Generate features for class zero\n",
    "feature1_class_zero = np.random.normal(loc=0, scale=1, size=class_0_data)\n",
    "feature2_class_zero = np.random.normal(loc=0, scale=1, size=class_0_data)\n",
    "\n",
    "\n",
    "# Generate features for class one\n",
    "feature1_class_one = np.random.normal(loc=1, scale=1, size=class_1_data)\n",
    "feature2_class_one = np.random.normal(loc=1, scale=1, size=class_1_data)\n",
    "\n",
    "\n",
    "# Create dataframes\n",
    "class_zero_df = pd.DataFrame({\n",
    "    'feature1': feature1_class_zero,\n",
    "    'feature2': feature2_class_zero,\n",
    "    'target': 0\n",
    "})\n",
    "\n",
    "class_one_df = pd.DataFrame({\n",
    "    'feature1': feature1_class_one,\n",
    "    'feature2': feature2_class_one,\n",
    "    'target': 1\n",
    "})\n",
    "\n",
    "# one the major method to balance the data in downsampling \n",
    "# major number of data\n",
    "df_majorup = df[df['target']==0]\n",
    "# minor number of data\n",
    "df_minorup = df[df['target'] == 1]\n",
    "\n",
    "df_minorup['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the same data and perform the downsample\n",
    "# downsample mean reduce the data and balance with minor datas\n",
    "from sklearn.utils import resample\n",
    "df_major_downsampled = resample(\n",
    "    df_major,\n",
    "    replace=False,  # sample without replacement\n",
    "    n_samples=len(df_minor), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_major_downsampled['target'].value_counts()\n",
    "# now major data has been reduce to 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
